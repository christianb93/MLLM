{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUcLPbZRl5LiW4FcjhDHte",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/christianb93/MLLM/blob/main/wiki/WikiTextTransformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kco8E6kYjTgz"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Import a few libraries that we need\n",
        "#\n",
        "import torch\n",
        "import os\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import re\n",
        "from torchtext.datasets import WikiText2\n",
        "import requests\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Install portalocker\n",
        "#\n",
        "#\n",
        "# IMPORTANT: you might have to restart the runtime to allow Python to detect the library\n",
        "#\n",
        "!pip3 install portalocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h28yW2rHlmZ-",
        "outputId": "21dd7ec5-f998-4fd1-e822-e5f671078e1a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (2.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Download a few files from my GitHub repository that we will need\n",
        "#\n",
        "files = [\"BPE.py\", \"util.py\"]\n",
        "URL = \"https://raw.githubusercontent.com/christianb93/MLLM/main/wiki/\"\n",
        "for file in files:\n",
        "    data = requests.get(URL+file)\n",
        "    with open(file, 'wb')as f:\n",
        "        f.write(data.content)\n",
        "  \n",
        "#\n",
        "# and import them\n",
        "# \n",
        "import BPE\n",
        "import util"
      ],
      "metadata": {
        "id": "j3F_Frv1jmt6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Define a few constants\n",
        "#\n",
        "MERGES = 6000\n",
        "VFILE= \"vocab.dat\"\n",
        "RFILE = \"rules.dat\"\n",
        "FULL_DATA = \"data.json\"\n",
        "TRAIN_DATA = \"train.json\"\n",
        "VAL_DATA = \"val.json\""
      ],
      "metadata": {
        "id": "vVMZQ2AblAFK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Download WikiText2 dataset \n",
        "#\n",
        "text = \"\"\n",
        "print(\"Downloading WikiText2 data set\")\n",
        "ds = WikiText2(split=\"train\")\n",
        "items = [_p for _p in ds]\n",
        "print(\"Cleaning data\")\n",
        "#\n",
        "# Each item is a paragraph as a long string. Clean and concatenate\n",
        "# \n",
        "for item in items:\n",
        "    # Remove trailing whitespace and @\n",
        "    item = re.sub(\"^\\s+\", \"\", item)\n",
        "    item = re.sub(\"@\", \"\", item)\n",
        "    item = re.sub(\"\\n\", \"\", item)\n",
        "    if not re.match(\"^=\", item):\n",
        "        text = text + item\n",
        "\n",
        "#\n",
        "# pretokenize to create a list of words\n",
        "#\n",
        "print(\"Pre-tokenizing text\")\n",
        "tokenizer = util.get_tokenizer()\n",
        "pre_tokenized_text = tokenizer(text)\n",
        "del text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGBNaZcwlKG-",
        "outputId": "b1fd5b5f-fb2a-437e-aac2-6f1ae56ea074"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading WikiText2 data set\n",
            "Cleaning data\n",
            "Pre-tokenizing text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = BPE.BPEEncoder(progress_bars = True)\n",
        "if not (os.path.exists(VFILE) and os.path.exists(RFILE)):\n",
        "    print(\"Initializing vocabulary\")\n",
        "    encoder.init_vocab(pre_tokenized_text)\n",
        "    print(f\"Start BPE learning phase ({MERGES} merges)\")\n",
        "    encoder.learn(s = MERGES, align_vocab = True)\n",
        "    encoder.save_rules(RFILE)\n",
        "    encoder.save_vocab(VFILE)\n",
        "else:\n",
        "    print(\"Loading vocabulary and rules\")\n",
        "    encoder.load_rules(RFILE)\n",
        "    encoder.load_vocab(VFILE)\n",
        "print(f\"Vocabulary size is now {len(encoder.get_vocab())}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu72ZRcRmKmP",
        "outputId": "38dd0b13-73b2-4951-da6d-57b65dd8032f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing vocabulary\n",
            "Counting words in input\n",
            "Building word frequencies\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating frequencies: 100%|██████████| 33227/33227 [00:00<00:00, 668374.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start BPE learning phase (6000 merges)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Merging: 100%|██████████| 6034/6034 [01:34<00:00, 64.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size is now 6400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# encode the input and save the results (or load from file)\n",
        "#\n",
        "if not os.path.exists(FULL_DATA):\n",
        "    encoded_text = []\n",
        "    encoder.compile_rules()\n",
        "    for word in tqdm(pre_tokenized_text, desc=\"Encoding\"):\n",
        "        encoded_text.extend(encoder.encode(word))\n",
        "    with open(FULL_DATA, \"w\") as f:\n",
        "        json.dump(encoded_text, f) \n",
        "else:\n",
        "    with open(FULL_DATA, \"r\") as f:\n",
        "        encoded_text = json.load(f) \n",
        "\n",
        "del pre_tokenized_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "899ByuU1m31u",
        "outputId": "72cc6a8c-f65d-4e80-b6fe-a825428a4ed2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Encoding: 100%|██████████| 2007146/2007146 [04:00<00:00, 8350.52it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# split into a training and a validation set\n",
        "#\n",
        "total_length = len(encoded_text)\n",
        "train_length = int(0.9*total_length)\n",
        "print(f\"Splitting file into {train_length} training items and {total_length - train_length} validation items\")\n",
        "with open(TRAIN_DATA, \"w\") as f:\n",
        "    json.dump(encoded_text[:train_length], f) \n",
        "with open(VAL_DATA, \"w\") as f:\n",
        "    json.dump(encoded_text[train_length:], f) \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rBDR1m0oO6-",
        "outputId": "77a293e9-5fda-40bd-d133-f8033c68cbc3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting file into 2360047 training items and 262228 validation items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Training parameters\n",
        "#\n",
        "LR = 0.0005\n",
        "DROPOUT = 0.2\n",
        "BATCH_SIZE = 512\n",
        "CONTEXT_SIZE = 48\n",
        "#\n",
        "# Create datasets for training and validation\n",
        "#\n",
        "train_ds = util.DataSet(window_size = CONTEXT_SIZE, encoder = None)\n",
        "val_ds  = util.DataSet(window_size =CONTEXT_SIZE, data = \"valid\", encoder = train_ds.get_vocab())\n",
        "print(f\"Using data set with {len(train_ds)} training items and {len(val_ds)} validation items\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts1Rf7vHoYO-",
        "outputId": "9f58710b-b3ff-4621-ecff-a675401b9725"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using data set with 2359998 training items and 262179 validation items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Create data loader. We drop the last batch to avoid spikes in the loss function, and we use two workers \n",
        "# which should be enough to keep most GPUs busy\n",
        "#\n",
        "training_data = torch.utils.data.DataLoader(train_ds, batch_size = BATCH_SIZE, collate_fn = util.collate_fn, shuffle = True, drop_last = True, num_workers = 2)\n",
        "val_data = torch.utils.data.DataLoader(val_ds, batch_size = BATCH_SIZE, collate_fn = util.collate_fn, shuffle = True, drop_last = True)\n"
      ],
      "metadata": {
        "id": "I-kVnRQzooiz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Our model\n",
        "# \n",
        "MODEL_DIM = 192\n",
        "FF_DIM = 1024\n",
        "HEADS = 8\n",
        "LAYERS = 4\n",
        "DROPOUT = 0.2\n",
        "\n",
        "#\n",
        "# A layer that adds a positional embedding to a given input. We use a fixed\n",
        "# sinusoidal embeddings as in the original \"Attention is all you need\" paper\n",
        "#\n",
        "class PosEmbeddingLayer(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, context_size, model_dim):\n",
        "        super().__init__()\n",
        "        _p = torch.arange(context_size , dtype=torch.float32).unsqueeze(dim = 1)\n",
        "        _i = torch.arange(0, model_dim , step = 2) / model_dim \n",
        "        x = _p / torch.pow(10000, _i)\n",
        "        self.register_buffer(\"_pe\", torch.zeros(context_size, model_dim))        \n",
        "        self._pe[:, 0::2] = torch.sin(x)\n",
        "        self._pe[:, 1::2] = torch.cos(x)\n",
        "        self._pe = torch.unsqueeze(self._pe, dim = 1)\n",
        "        self._model_dim = model_dim\n",
        "        self._context_size = context_size\n",
        "        \n",
        "    #\n",
        "    # Shape of input: (sequence length, batch_size, model_dim) \n",
        "    #\n",
        "    def forward(self, x):\n",
        "        assert len(x.shape) == 3, \"Shape (L, B, D) required\"\n",
        "        assert x.shape[2] == self._model_dim, \"Last dimension needs to be model dimension\"\n",
        "        L = x.shape[0]\n",
        "        assert L <= self._context_size, \"Length exceeds context size\"\n",
        "        pe = self._pe[:L, :, :]\n",
        "        return x + pe\n",
        "\n",
        "#\n",
        "# A simple decoder-only transformer model, with a learned\n",
        "# word embedding, a sinusoidal positional embedding and a linear\n",
        "# output layer\n",
        "#\n",
        "class Model(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, model_dim = MODEL_DIM, context_size = CONTEXT_SIZE, ff_dim = FF_DIM, heads = HEADS, layers = LAYERS, dropout = DROPOUT):\n",
        "        super().__init__()\n",
        "        self._word_embedding = torch.nn.Embedding(vocab_size, model_dim)\n",
        "        self._pe_embedding = PosEmbeddingLayer(context_size, model_dim)\n",
        "        layer = torch.nn.TransformerEncoderLayer(d_model = model_dim, nhead = heads, dim_feedforward = ff_dim, dropout = dropout)\n",
        "        self._transformer = torch.nn.TransformerEncoder(layer, num_layers = layers)\n",
        "        self._linear = torch.nn.Linear(in_features = model_dim, out_features = vocab_size)\n",
        "        self._model_dim = model_dim\n",
        "        self._context_size = context_size\n",
        "        self._vocab_size = vocab_size\n",
        "        cached_mask = torch.tril(torch.ones(context_size, context_size)*(-1)*float('inf'), diagonal = -1).t()\n",
        "        self.register_buffer(\"_cached_mask\", cached_mask)\n",
        "    \n",
        "    #\n",
        "    # Create a causal self-attention mask\n",
        "    #\n",
        "    def get_self_attention_mask(self):\n",
        "        return self._cached_mask\n",
        "        \n",
        "    #\n",
        "    # Shape of input: (L, B)\n",
        "    # \n",
        "    def forward(self, x):\n",
        "        assert len(x.shape) == 2, \"Expecting two-dimensional input\"\n",
        "        (L, B) = x.shape\n",
        "        x = self._word_embedding(x) # shape (L, B, model_dim)\n",
        "        x = self._pe_embedding(x) \n",
        "        #\n",
        "        # Mask input. As we have registered this is a buffer, it\n",
        "        # should already be on the same device as the model\n",
        "        #\n",
        "        mask = self.get_self_attention_mask()[:L, :L]\n",
        "        x = self._transformer(x, mask = mask)\n",
        "        return self._linear(x)        \n",
        "\n",
        "    #\n",
        "    # Get context size\n",
        "    #\n",
        "    def get_context_size(self):\n",
        "        return self._context_size\n",
        "\n"
      ],
      "metadata": {
        "id": "ClIEqOzbo1_d"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "V = len(train_ds.get_vocab())\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = Model(vocab_size = V, model_dim = MODEL_DIM, context_size = CONTEXT_SIZE,  dropout = DROPOUT).to(device)\n",
        "model.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhclBRudpGTx",
        "outputId": "d005c13e-454c-4977-be5e-2349acf88781"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (_word_embedding): Embedding(6400, 192)\n",
              "  (_pe_embedding): PosEmbeddingLayer()\n",
              "  (_transformer): TransformerEncoder(\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x TransformerEncoderLayer(\n",
              "        (self_attn): MultiheadAttention(\n",
              "          (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
              "        )\n",
              "        (linear1): Linear(in_features=192, out_features=1024, bias=True)\n",
              "        (dropout): Dropout(p=0.2, inplace=False)\n",
              "        (linear2): Linear(in_features=1024, out_features=192, bias=True)\n",
              "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout1): Dropout(p=0.2, inplace=False)\n",
              "        (dropout2): Dropout(p=0.2, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (_linear): Linear(in_features=192, out_features=6400, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "print(f\"Training for {EPOCHS} epochs\")\n",
        "print(f\"Using device {device} and batch size {BATCH_SIZE}, lr = {LR} (min {LR*0.1}), dropout = {DROPOUT}\")\n",
        "start_time = time.time()\n",
        "torch.set_float32_matmul_precision('high')\n",
        "losses, val_losses = util.train(model, EPOCHS, batch_size = BATCH_SIZE,\n",
        "               train_data_loader = training_data, val_data_loader = val_data, \n",
        "               device = device, log_steps = 250, \n",
        "               lr = LR, lr_min = LR*0.1, autocast = True)\n",
        "end_time = time.time()\n",
        "print(f\"Total training time: {end_time - start_time}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Co1fA39gq-VC",
        "outputId": "456d9c1a-a183-42c9-df11-499f8560e96f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 3 epochs\n",
            "Using device cuda and batch size 512, lr = 0.0005 (min 5e-05), dropout = 0.2\n",
            "Steps per epoch: 4609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:   5%|▌         | 251/4609 [00:29<07:59,  9.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 250 steps (0.117 seconds per step), current loss is 6.037606716156006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  11%|█         | 501/4609 [00:57<07:46,  8.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 500 steps (0.112 seconds per step), current loss is 5.241933345794678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  16%|█▋        | 751/4609 [01:26<07:39,  8.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 750 steps (0.116 seconds per step), current loss is 4.964645862579346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  22%|██▏       | 1001/4609 [01:55<06:53,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 1000 steps (0.117 seconds per step), current loss is 4.779524326324463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  27%|██▋       | 1251/4609 [02:24<06:18,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 1250 steps (0.115 seconds per step), current loss is 4.606695652008057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  33%|███▎      | 1501/4609 [02:53<05:55,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 1500 steps (0.115 seconds per step), current loss is 4.497130393981934\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  38%|███▊      | 1751/4609 [03:22<05:43,  8.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 1750 steps (0.116 seconds per step), current loss is 4.441714763641357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  43%|████▎     | 2001/4609 [03:50<04:53,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 2000 steps (0.113 seconds per step), current loss is 4.370137691497803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  49%|████▉     | 2251/4609 [04:19<04:25,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 2250 steps (0.113 seconds per step), current loss is 4.298154830932617\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  54%|█████▍    | 2501/4609 [04:47<04:02,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 2500 steps (0.113 seconds per step), current loss is 4.228367328643799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  60%|█████▉    | 2751/4609 [05:15<03:36,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 2750 steps (0.114 seconds per step), current loss is 4.217047691345215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  65%|██████▌   | 3001/4609 [05:44<03:02,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 3000 steps (0.114 seconds per step), current loss is 4.180335998535156\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  71%|███████   | 3251/4609 [06:12<02:33,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 3250 steps (0.113 seconds per step), current loss is 4.125865459442139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  76%|███████▌  | 3501/4609 [06:41<02:04,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 3500 steps (0.115 seconds per step), current loss is 4.051138401031494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  81%|████████▏ | 3751/4609 [07:09<01:41,  8.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 3750 steps (0.114 seconds per step), current loss is 4.076267719268799\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  87%|████████▋ | 4001/4609 [07:38<01:08,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 4000 steps (0.114 seconds per step), current loss is 4.061057090759277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  92%|█████████▏| 4251/4609 [08:06<00:40,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 4250 steps (0.113 seconds per step), current loss is 3.9958536624908447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0:  98%|█████████▊| 4501/4609 [08:35<00:12,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 4500 steps (0.115 seconds per step), current loss is 3.9946582317352295\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 4609/4609 [08:47<00:00,  8.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed epoch 0, validation loss is 4.8175, duration 570.89 seconds, current learning rate is 0.000390\n",
            "Saved model checkpoint at model_0.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   3%|▎         | 142/4609 [00:16<08:24,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 4750 steps (0.290 seconds per step), current loss is 4.021607398986816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:   9%|▊         | 392/4609 [00:45<07:51,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 5000 steps (0.114 seconds per step), current loss is 3.9419784545898438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  14%|█▍        | 642/4609 [01:13<07:58,  8.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 5250 steps (0.114 seconds per step), current loss is 3.921334981918335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  19%|█▉        | 892/4609 [01:42<06:55,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 5500 steps (0.116 seconds per step), current loss is 3.9249675273895264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  25%|██▍       | 1142/4609 [02:11<06:29,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 5750 steps (0.114 seconds per step), current loss is 3.914746046066284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  30%|███       | 1392/4609 [02:39<06:02,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 6000 steps (0.114 seconds per step), current loss is 3.9185609817504883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  36%|███▌      | 1642/4609 [03:08<05:58,  8.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 6250 steps (0.116 seconds per step), current loss is 3.869535207748413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  41%|████      | 1892/4609 [03:37<05:11,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 6500 steps (0.114 seconds per step), current loss is 3.870013952255249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  46%|████▋     | 2142/4609 [04:05<04:38,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 6750 steps (0.115 seconds per step), current loss is 3.90073561668396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  52%|█████▏    | 2392/4609 [04:34<04:10,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 7000 steps (0.116 seconds per step), current loss is 3.8645694255828857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  57%|█████▋    | 2642/4609 [05:04<04:02,  8.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 7250 steps (0.116 seconds per step), current loss is 3.814094305038452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  63%|██████▎   | 2892/4609 [05:33<03:14,  8.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 7500 steps (0.119 seconds per step), current loss is 3.865384340286255\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  68%|██████▊   | 3142/4609 [06:02<02:53,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 7750 steps (0.115 seconds per step), current loss is 3.831814765930176\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  74%|███████▎  | 3392/4609 [06:31<02:17,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 8000 steps (0.116 seconds per step), current loss is 3.7883388996124268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  79%|███████▉  | 3642/4609 [07:00<01:48,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 8250 steps (0.115 seconds per step), current loss is 3.8557214736938477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  84%|████████▍ | 3892/4609 [07:29<01:24,  8.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 8500 steps (0.117 seconds per step), current loss is 3.7882261276245117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  90%|████████▉ | 4142/4609 [07:58<00:53,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 8750 steps (0.115 seconds per step), current loss is 3.806849718093872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  95%|█████████▌| 4392/4609 [08:27<00:25,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 9000 steps (0.115 seconds per step), current loss is 3.7906405925750732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 4609/4609 [08:53<00:00,  8.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed epoch 1, validation loss is 4.8115, duration 576.60 seconds, current learning rate is 0.000164\n",
            "Saved model checkpoint at model_1.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:   1%|          | 33/4609 [00:04<09:02,  8.43it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 9250 steps (0.295 seconds per step), current loss is 3.764889717102051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:   6%|▌         | 283/4609 [00:33<08:10,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 9500 steps (0.116 seconds per step), current loss is 3.7943499088287354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  12%|█▏        | 533/4609 [01:01<07:38,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 9750 steps (0.113 seconds per step), current loss is 3.7868385314941406\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  17%|█▋        | 783/4609 [01:30<07:20,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 10000 steps (0.114 seconds per step), current loss is 3.776592493057251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  22%|██▏       | 1033/4609 [01:58<06:41,  8.91it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 10250 steps (0.114 seconds per step), current loss is 3.7608869075775146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  28%|██▊       | 1283/4609 [02:27<06:15,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 10500 steps (0.114 seconds per step), current loss is 3.768221616744995\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  33%|███▎      | 1533/4609 [02:56<05:51,  8.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 10750 steps (0.116 seconds per step), current loss is 3.7297658920288086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  39%|███▊      | 1783/4609 [03:25<05:18,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 11000 steps (0.115 seconds per step), current loss is 3.7596170902252197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  44%|████▍     | 2033/4609 [03:53<04:54,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 11250 steps (0.115 seconds per step), current loss is 3.7774746417999268\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  50%|████▉     | 2283/4609 [04:22<04:30,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 11500 steps (0.116 seconds per step), current loss is 3.733886480331421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  55%|█████▍    | 2533/4609 [04:51<03:54,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 11750 steps (0.115 seconds per step), current loss is 3.755983352661133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  60%|██████    | 2783/4609 [05:20<03:35,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 12000 steps (0.116 seconds per step), current loss is 3.7482786178588867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  66%|██████▌   | 3033/4609 [05:49<03:00,  8.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 12250 steps (0.116 seconds per step), current loss is 3.7699458599090576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  71%|███████   | 3283/4609 [06:18<02:31,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 12500 steps (0.116 seconds per step), current loss is 3.7269277572631836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  77%|███████▋  | 3533/4609 [06:47<02:03,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 12750 steps (0.116 seconds per step), current loss is 3.7200326919555664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  82%|████████▏ | 3783/4609 [07:16<01:38,  8.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 13000 steps (0.116 seconds per step), current loss is 3.7289021015167236\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  88%|████████▊ | 4033/4609 [07:45<01:06,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 13250 steps (0.116 seconds per step), current loss is 3.759183645248413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  93%|█████████▎| 4283/4609 [08:13<00:37,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 13500 steps (0.115 seconds per step), current loss is 3.7053349018096924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2:  98%|█████████▊| 4533/4609 [08:42<00:08,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 13750 steps (0.116 seconds per step), current loss is 3.758755922317505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 4609/4609 [08:52<00:00,  8.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed epoch 2, validation loss is 4.8143, duration 575.48 seconds, current learning rate is 0.000050\n",
            "Saved model checkpoint at model_2.pt\n",
            "Total training time: 1723.1558029651642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses) \n",
        "for epoch, loss in enumerate(val_losses):\n",
        "    print(f\"Epoch {epoch} ---> validation loss {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "DDd5KP94rZf2",
        "outputId": "95fca531-9d1f-47af-e364-96b0b46dc211"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 ---> validation loss 4.8175\n",
            "Epoch 1 ---> validation loss 4.8115\n",
            "Epoch 2 ---> validation loss 4.8143\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Sample using nucleus sampling\n",
        "#\n",
        "def predict(prompt = \". \", length = 200, temperature = 0.7):\n",
        "    sample_ids = util.do_sample(prompt, model, encoder, device = device, method = 3, length = length, temperature = temperature)\n",
        "    sample = util.beautify_decoder_output(encoder.decode(sample_ids))\n",
        "    #\n",
        "    # Strip off prompt again if we have used the default prompt\n",
        "    #\n",
        "    if prompt == \". \":\n",
        "        sample = sample[len(prompt):]\n",
        "\n",
        "    return sample\n",
        "\n"
      ],
      "metadata": {
        "id": "zv4Kc1hvzOjP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = predict()\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "display(Markdown(f\"{sample}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "m5s5IBbNzjYx",
        "outputId": "b846076f-72e2-436e-d7f1-020d3c6be5b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "For the time, the actors of the <unk> 's first minister. The people involved in the commune with a second verse, including <unk>, a <unk> and a <unk>, <unk>, which has to <unk> <unk> and to help him a <unk>. He ended his claim to his parties, and was an English was the most memory of the year. He is a supporter and thus fever in his own life. He was a second son of Bobby Hall of Fame, and played as a member of the leadership in the Japanese role of the Garden Fill. Federer also received the first title of the Australian Open in the finals, including the Madonna Open, the Duke of Florence, and his first tournament. Federer won the final, losing to the finals, having scored a record nine times to five consecutive weeks before losing 19, in the Bir 'Shoot <unk>, an injury. Bellers were <unk>, they were defeated "
          },
          "metadata": {}
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0IefYY9jOHdYoJjx/f79h"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iOtf_R5j5Wtt"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is our RNN. We have already seen the forward method in the last blog post. Putting together this class is straightforward, the only point which requires some care is to wrap the parameters that we want to be trainable in a *torch.nn.Parameter* instance so that PyTorch registers them as parameters."
      ],
      "metadata": {
        "id": "GGkHH_9jFiEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RNN(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_hidden):\n",
        "    super().__init__()\n",
        "    self._d_hidden = d_hidden\n",
        "    self._d_in = d_in\n",
        "    self._w_ih = torch.nn.Parameter(torch.randn((d_hidden, d_in)))\n",
        "    self._b_ih = torch.nn.Parameter(torch.randn(d_hidden))\n",
        "    self._w_hh = torch.nn.Parameter(torch.randn((d_hidden, d_hidden)))\n",
        "    self._b_hh = torch.nn.Parameter(torch.randn(d_hidden))\n",
        "\n",
        "  def forward(self, x, h = None):\n",
        "    L = x.shape[0]\n",
        "    if h is None:\n",
        "        h = torch.zeros(self._d_hidden)\n",
        "    out = []\n",
        "    for t in range(L):\n",
        "      h = torch.tanh(x[t] @ self._w_ih.t() + self._b_ih + h @ self._w_hh.t() + self._b_hh)\n",
        "      out.append(h)\n",
        "    return torch.stack(out), h"
      ],
      "metadata": {
        "id": "jou65wr-5iVY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To have a full model, we still need to add a linear layer on top of the RNN which converts the data back from the hidden dimension into the dimension corresponding to the vocabulary. So our full model will consist of an RNN layer followed by a linear layer. As usual, the final softmax is not included but will be taken care of in the loss function."
      ],
      "metadata": {
        "id": "bVbyZJDFF2wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(torch.nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_hidden):\n",
        "    self._d_hidden = d_hidden\n",
        "    self._d_in = d_in\n",
        "    super().__init__()\n",
        "    self._rnn = RNN(d_in = d_in, d_hidden = d_hidden)\n",
        "    self._linear = torch.nn.Linear(in_features = d_hidden, out_features = d_in)\n",
        "\n",
        "  def forward(self, x, h = None):\n",
        "    rnn_out, hidden = self._rnn(x, h)\n",
        "    out = self._linear(rnn_out)\n",
        "    return out, hidden  \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "B2ClkLrqBWZe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we need a dataset. The dataset actually implements the teacher forcing. Specifically, given an input sequence which is simply a short sequence of consecutive numbers, we form the corresponding sequence of targets by shifting the inputs to the rights. If, for instance, the inputs are [0,1,2,3,4], the corresponding target is [1,2,3,4,5]."
      ],
      "metadata": {
        "id": "zhQW35VrGKaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CounterDataSet(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, V, L):\n",
        "    super().__init__()\n",
        "    self._V = V\n",
        "    self._L = L\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    if not index < len(self):\n",
        "      raise KeyError\n",
        "    #\n",
        "    # Input at index is the sequence of length L \n",
        "    # starting at index\n",
        "    #\n",
        "    inputs =   torch.tensor([i for i in range(index, index + self._L)], dtype = torch.long)\n",
        "    targets = torch.tensor([i for i in range(index + 1, index + self._L + 1)], dtype=torch.long)\n",
        "    inputs = torch.nn.functional.one_hot(inputs, num_classes = self._V).to(torch.float32)\n",
        "    return inputs, targets\n",
        "\n",
        "  def __len__(self):\n",
        "    return self._V - self._L\n"
      ],
      "metadata": {
        "id": "kUsL7UuM6ffR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us try this out. We create a dataset with a small value of V that still allows for visual inspection and print the first item. We see that the input (which uses one-hot encoding) represents the sequence [0,1,2,3], whereas the corresponding targets are [1,2,3,4]"
      ],
      "metadata": {
        "id": "cJG81GE9Gqt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = CounterDataSet(V = 10, L = 4)\n",
        "#\n",
        "# Print last item\n",
        "#\n",
        "x, y = ds[0]\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqyCJdqy74jm",
        "outputId": "4f9f5754-6c63-4b97-aec6-7333779a2650"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be able to train our model, we still need a bit of boilerplate code. The collate function will be used to assemble a set of items into a batch. Note that we use the second dimension as the batch dimension. In the training function, we need to keep in mind that the output of the model will be of shape (L,B,V) whereas the targets (which are the labels only) have shape (L,B). To be able to feed this into the loss function, we reshape the inputs and targets to have dimensions (L x B, V) and (L x B), which is what the loss function expects.\n",
        "\n",
        "Of course our data set is very small and the network will simply memorize all training samples. Our training run is very short and should only take a few seconds, even on a CPU."
      ],
      "metadata": {
        "id": "qqDMpo7eHBdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(list):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for index, [x, y] in enumerate(list):\n",
        "        Y.append(y)\n",
        "        X.append(x)\n",
        "    #\n",
        "    # Stack along batch dimension\n",
        "    #        \n",
        "    X = torch.stack(X, dim = 1)\n",
        "    Y = torch.stack(Y, dim = 1)\n",
        "    return X, Y \n",
        "\n",
        "loader = torch.utils.data.DataLoader(ds, batch_size = 2, shuffle = False, collate_fn = collate_fn)\n",
        "iter = loader.__iter__()\n",
        "x, y = next(iter)\n",
        "#\n",
        "# Inputs are of dimension (L, B, V)\n",
        "# Targets are of dimension (L, B)\n",
        "#\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(x[:,0,:])\n",
        "print(y[:,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdS17au4-uXK",
        "outputId": "19a5fc3f-4799-477d-a0eb-eb56d4c11409"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2, 10])\n",
            "torch.Size([4, 2])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]])\n",
            "tensor([1, 2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epochs, train_data_loader, lr = 0.025, device = \"cpu\", loss_fn = torch.nn.functional.cross_entropy):\n",
        "    losses = []\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "    lr_lambda = lambda epoch: (epochs - epoch) / epochs\n",
        "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda, verbose = False)\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        items_in_epoch = 0\n",
        "        for X, Y in train_data_loader:\n",
        "            items_in_epoch = items_in_epoch + 1\n",
        "            f, hidden = model(X.to(device))\n",
        "            targets = Y.to(device)\n",
        "            #\n",
        "            # f is the model output and has shape (L, B, V)\n",
        "            # targets are the targets and have shape (L, B) \n",
        "            # so we first flatten them\n",
        "            #\n",
        "            V = f.shape[2]\n",
        "            f = f.view(-1, V)\n",
        "            targets = targets.flatten()\n",
        "            loss = loss_fn(f, targets)            \n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            losses.append(loss.item())\n",
        "            epoch_loss = epoch_loss + loss.item()\n",
        "\n",
        "        epoch_loss = epoch_loss / items_in_epoch\n",
        "        print(f\"Completed epoch {epoch}, mean loss in epoch is {epoch_loss}\")\n",
        "        scheduler.step()\n",
        "\n",
        "    return losses\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device {device}\")\n",
        "V = 128\n",
        "L = 6\n",
        "D_HIDDEN = 32\n",
        "model = MyModel(d_in = V, d_hidden = D_HIDDEN)\n",
        "model = model.to(device)\n",
        "ds = CounterDataSet(V = V, L = L)\n",
        "BATCH_SIZE = len(ds) // 2\n",
        "\n",
        "training_data = torch.utils.data.DataLoader(ds, batch_size = BATCH_SIZE, shuffle = True, collate_fn = collate_fn, drop_last = True)\n",
        "losses = train(model, lr=0.1, epochs=25, train_data_loader = training_data, device = device)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(losses)  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "f5GtdPqW9h4V",
        "outputId": "067a2311-ad41-4cf7-ede5-e09bfe0a6426"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device cpu\n",
            "Completed epoch 0, mean loss in epoch is 4.920872211456299\n",
            "Completed epoch 1, mean loss in epoch is 3.8525729179382324\n",
            "Completed epoch 2, mean loss in epoch is 3.0924001932144165\n",
            "Completed epoch 3, mean loss in epoch is 2.4735904932022095\n",
            "Completed epoch 4, mean loss in epoch is 2.039393365383148\n",
            "Completed epoch 5, mean loss in epoch is 1.6201226711273193\n",
            "Completed epoch 6, mean loss in epoch is 1.2232605814933777\n",
            "Completed epoch 7, mean loss in epoch is 1.0380517840385437\n",
            "Completed epoch 8, mean loss in epoch is 0.7445066273212433\n",
            "Completed epoch 9, mean loss in epoch is 0.5589053630828857\n",
            "Completed epoch 10, mean loss in epoch is 0.4509558528661728\n",
            "Completed epoch 11, mean loss in epoch is 0.345085009932518\n",
            "Completed epoch 12, mean loss in epoch is 0.2476726993918419\n",
            "Completed epoch 13, mean loss in epoch is 0.1986043006181717\n",
            "Completed epoch 14, mean loss in epoch is 0.16385888308286667\n",
            "Completed epoch 15, mean loss in epoch is 0.13710297644138336\n",
            "Completed epoch 16, mean loss in epoch is 0.1231643557548523\n",
            "Completed epoch 17, mean loss in epoch is 0.11977362632751465\n",
            "Completed epoch 18, mean loss in epoch is 0.0941416583955288\n",
            "Completed epoch 19, mean loss in epoch is 0.07940812036395073\n",
            "Completed epoch 20, mean loss in epoch is 0.07390766963362694\n",
            "Completed epoch 21, mean loss in epoch is 0.0682312361896038\n",
            "Completed epoch 22, mean loss in epoch is 0.06482874602079391\n",
            "Completed epoch 23, mean loss in epoch is 0.06149347126483917\n",
            "Completed epoch 24, mean loss in epoch is 0.05994946323335171\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5d59c411f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we sample from the model. We use the sequence 7,8,9,10 as prompt and do of course expect that the model correctly predicts 11 as the next value."
      ],
      "metadata": {
        "id": "4OFge3eJIHZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Input is the sequence [7,8,9,10]\n",
        "#\n",
        "input = torch.tensor([i for i in range(7, 11)], dtype=torch.long)\n",
        "input = torch.nn.functional.one_hot(input, num_classes = V).to(torch.float32)\n",
        "out, hidden = model(input.to(device))\n",
        "#\n",
        "# Output has shape (L, V) \n",
        "#\n",
        "print(f\"Shape out output: {out.shape}\")\n",
        "#\n",
        "# Strip off last output and apply softmax\n",
        "# to obtain a probability distribution p of length V\n",
        "#\n",
        "p = torch.softmax(out[-1], dim = -1)\n",
        "print(p.shape)\n",
        "#\n",
        "# Predict\n",
        "#\n",
        "guess = torch.argmax(p).item()\n",
        "print(guess)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKgKX5LvEQ9G",
        "outputId": "d54dc822-9a54-4518-ac10-c195d029cff0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape out output: torch.Size([4, 128])\n",
            "torch.Size([128])\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Predict next value, reusing the hidden layer\n",
        "#\n",
        "input = torch.tensor([11], dtype=torch.long)\n",
        "input = torch.nn.functional.one_hot(input, num_classes = V).to(torch.float32)\n",
        "out, _ = model(input.to(device), hidden)\n",
        "\n",
        "p = torch.softmax(out[-1], dim = -1)\n",
        "guess = torch.argmax(p).item()\n",
        "print(guess)"
      ],
      "metadata": {
        "id": "CY5pSRHEMPIt",
        "outputId": "6ca9f8b2-9d7e-4222-fd8c-be3f36aeeef9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n"
          ]
        }
      ]
    }
  ]
}
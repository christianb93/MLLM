{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37566b11-bf6a-4f65-bb5c-9272f5e3bd33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37566b11-bf6a-4f65-bb5c-9272f5e3bd33",
    "outputId": "37af9d3c-da88-450a-bd63-886d4849786b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Check that PyTorch is properly installed\n",
    "#\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5c4d8c1-a8a6-4ee2-b812-549f6bfd271f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5c4d8c1-a8a6-4ee2-b812-549f6bfd271f",
    "outputId": "42c1b774-8eb0-4f55-a91f-77f9fab5863e"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import torchtext\n",
    "    import portalocker\n",
    "except:\n",
    "    !pip3 install torchtext portalocker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eed12e-1353-44aa-a064-5696951c4506",
   "metadata": {
    "id": "41eed12e-1353-44aa-a064-5696951c4506"
   },
   "source": [
    "First we need to download the WikiText2 dataset. The dataset consists of individual paragraphs, some of which are titles. We go through all paragraphs, clean them, and add all remaining paragraphs into a list. Note that we maintain the structure of paragraphs instead of merging all of them into a single list, as we want to avoid creating center and context pairs that span across paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0815b915-2fa3-43f1-843e-c05c01db1eac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0815b915-2fa3-43f1-843e-c05c01db1eac",
    "outputId": "78e33413-1e13-457e-c968-739c04b00628",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'early', 'hours', 'of', '7', 'october', 'the', 'allied', 'artillery', 'and', 'mortar', 'bombardment', 'began', ',', 'targeting', 'chinese', 'positions', 'on', 'the', 'hinge', '.', 'hassett', 'moved', 'the', '3', 'rar', 'tactical', 'headquarters', 'on', 'to', 'hill', '317', 'just', 'before', 'the', 'assaulting', 'troops', 'stepped', 'off', 'the', 'line', 'of', 'departure', ',', 'allowing', 'him', 'to', 'direct', 'the', 'battle', 'from', 'a', 'forward', 'position', 'and', 'to', 'co', '-', '<unk>', 'fire', 'support', '.', 'waiting', 'for', 'the', 'fog', 'to', 'lift', 'so', 'that', 'the', 'artillery', 'could', 'fire', 'until', 'the', 'last', 'safe', 'moment', ',', 'the', 'attack', 'finally', 'began', 'at', '08', '00', '.', 'b', 'company', 'moved', 'off', 'down', 'the', '<unk>', ',', 'with', 'two', '-', 'up', 'and', 'one', '-', 'in', '-', 'depth', ',', 'using', 'the', 'trees', 'and', 'long', 'grass', 'for', 'concealment', '.', 'initially', 'it', 'seemed', 'that', 'the', 'chinese', 'had', 'withdrawn', 'during', 'the', 'night', ',', 'when', 'suddenly', 'the', 'lead', 'australian', 'platoons', 'were', '<unk>', 'by', 'small', 'arms', 'fire', 'from', 'their', 'rear', '.', 'a', 'series', 'of', 'intense', 'fire', '-', 'fights', 'ensued', 'as', 'the', 'australians', 'fought', 'back', 'and', 'by', '09', '20', 'the', 'hinge', 'finally', 'fell', ',', 'with', 'the', 'australians', 'losing', 'two', 'killed', 'and', '20', 'wounded', '.', 'chinese', 'casualties', 'included', 'more', 'than', '20', 'killed', '.', 'as', 'a', 'result', 'of', 'the', 'fighting', 'captain', 'henry', 'nicholls', 'and', 'lieutenant', 'jim', 'hughes', 'were', 'awarded', 'the', 'military', 'cross', ',', 'while', '<unk>', 'j', '.', 'park', 'and', '<unk>', '<unk>', 'bosworth', 'were', 'awarded', 'the', 'military', 'medal', '.', 'yet', 'even', 'as', 'the', 'surviving', 'chinese', 'withdrew', ',', 'artillery', 'and', 'mortar', 'fire', 'began', 'to', 'fall', 'on', 'the', 'hinge', '.', 'b', 'company', 'moved', 'quickly', 'to', 'consolidate', 'the', 'position', ',', 'but', 'were', 'hampered', 'by', 'the', 'shelling', ',', 'while', 'they', 'now', 'faced', 'a', 'pressing', 'shortage', 'of', 'ammunition', 'and', 'difficulties', 'evacuating', 'their', 'casualties', '.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torchtext\n",
    "import collections\n",
    "\n",
    "\n",
    "def to_paragraphs(_items, tokenizer):\n",
    "    paragraphs = []\n",
    "    for item in _items:\n",
    "        # Remove trailing whitespace and special characters\n",
    "        item = re.sub(\"^\\s+\", \"\", item)\n",
    "        item = re.sub(\"@\", \"\", item)\n",
    "        if not re.match(\"^=\", item):\n",
    "            p = tokenizer(item)\n",
    "            if len(p):\n",
    "                paragraphs.append(p)\n",
    "                        \n",
    "    return paragraphs\n",
    "\n",
    "#\n",
    "# Build list of paragraphs and print a sample\n",
    "#\n",
    "ds = torchtext.datasets.WikiText2(split=\"train\")\n",
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "paragraphs = to_paragraphs(ds, tokenizer)\n",
    "print(paragraphs[5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c296d54-d168-4bfd-b1e8-1242d6f33ac6",
   "metadata": {
    "id": "7c296d54-d168-4bfd-b1e8-1242d6f33ac6"
   },
   "source": [
    "Next we again tokenize the text and build a vocabulary. However, this time we will ignore all words that appear less than a given number of times in the text, and instead use a special token in the vocabulary that will be used for all token that are not in the vocabulary during encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa415ca2-e674-4acb-8565-71a41798a809",
   "metadata": {
    "id": "fa415ca2-e674-4acb-8565-71a41798a809",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vocab(paragraphs, min_freq = 50):\n",
    "        vocab = torchtext.vocab.build_vocab_from_iterator(paragraphs, min_freq=min_freq, specials=[\"<unk>\"])\n",
    "        vocab.set_default_index(vocab[\"<unk>\"])\n",
    "        return vocab\n",
    "\n",
    "def encode_paragraphs(paragraphs, vocab):\n",
    "    return [[vocab[_token] for _token in p] for p in paragraphs]\n",
    "\n",
    "vocab = build_vocab(paragraphs)\n",
    "encoded_paragraphs = encode_paragraphs(paragraphs, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9a02a-a2d9-421c-880b-b1250f0ed602",
   "metadata": {
    "id": "08a9a02a-a2d9-421c-880b-b1250f0ed602"
   },
   "source": [
    "The next step in the processing is to create pairs consisting of a center token and a list of context tokens. We will do this paragraph for paragraph and later skip outputs which are two short. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee1b3b7-0df9-4890-843b-d156d64a310e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dee1b3b7-0df9-4890-843b-d156d64a310e",
    "outputId": "1d1c526f-b883-4b4d-cbd9-f1842239b303",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This', ['is', 'a'])\n",
      "('is', ['This', 'a', 'short'])\n",
      "('a', ['This', 'is', 'short', 'test'])\n",
      "('short', ['is', 'a', 'test', 'paragraph'])\n",
      "('test', ['a', 'short', 'paragraph', 'to'])\n",
      "('paragraph', ['short', 'test', 'to', 'try'])\n",
      "('to', ['test', 'paragraph', 'try', 'out'])\n",
      "('try', ['paragraph', 'to', 'out', 'things'])\n",
      "('out', ['to', 'try', 'things'])\n",
      "('things', ['try', 'out'])\n"
     ]
    }
   ],
   "source": [
    "def yield_context(paragraphs, window_size = 8):\n",
    "    for p in paragraphs:\n",
    "        half = window_size // 2\n",
    "        #\n",
    "        # If we are not yet at the last token in the paragraph, \n",
    "        # yield window and advance center. \n",
    "        #\n",
    "        for index, center in  enumerate(p):\n",
    "            context = p[max(0, index - half):index]\n",
    "            context.extend(p[index + 1:min(len(p), index + half + 1)])\n",
    "            yield center, context\n",
    "\n",
    "test_paragraphs = [[\"This\", \"is\", \"a\", \"short\", \"test\", \"paragraph\", \"to\", \"try\", \"out\", \"things\"]]\n",
    "iter = yield_context(test_paragraphs, window_size = 4)\n",
    "for i in range(10):\n",
    "  print(next(iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca21a6e-062a-4206-a78a-1adaa24cc130",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ca21a6e-062a-4206-a78a-1adaa24cc130",
    "outputId": "61bba339-4397-4b5a-d3bb-0b54279810b5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['17', 'team', 'of', '24'] players [',', '<unk>', 'from', 'an']\n",
      "['team', 'of', '24', 'players'] , ['<unk>', 'from', 'an', 'initial']\n",
      "['of', '24', 'players', ','] <unk> ['from', 'an', 'initial', 'pool']\n",
      "['24', 'players', ',', '<unk>'] from ['an', 'initial', 'pool', 'of']\n",
      "['players', ',', '<unk>', 'from'] an ['initial', 'pool', 'of', '49']\n",
      "[',', '<unk>', 'from', 'an'] initial ['pool', 'of', '49', 'young']\n",
      "['<unk>', 'from', 'an', 'initial'] pool ['of', '49', 'young', 'women']\n",
      "['from', 'an', 'initial', 'pool'] of ['49', 'young', 'women', '.']\n",
      "['an', 'initial', 'pool', 'of'] 49 ['young', 'women', '.', 'two']\n",
      "['initial', 'pool', 'of', '49'] young ['women', '.', 'two', 'girls']\n"
     ]
    }
   ],
   "source": [
    "def print_sample(center, context):\n",
    "    left_context = context[:len(context) // 2]\n",
    "    right_context = context[len(context) // 2:]\n",
    "    print(f\"{[vocab.lookup_token(idx) for idx in left_context]} {vocab.lookup_token(center)} {[vocab.lookup_token(idx) for idx in right_context]}\")\n",
    "    \n",
    "iter = yield_context(encoded_paragraphs)\n",
    "#\n",
    "# Advance by a few items, then print a few examples\n",
    "#\n",
    "for i in range(10800):\n",
    "    next(iter)\n",
    "for i in range(10):\n",
    "    center, context = next(iter)\n",
    "    if len(context) != 8:\n",
    "        continue\n",
    "    print_sample(center, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f092890-a369-47e7-94f3-5bc44187bec5",
   "metadata": {
    "id": "4f092890-a369-47e7-94f3-5bc44187bec5"
   },
   "source": [
    "We are now ready to put all this into a PyTorch data set, use a data loader to load a batch and print a few examples from the batch to verify that our code works. This is not an introduction into datasets, but basically a dataset is an object that implements *__getitem__* and *__len__* so that it can be handled by a data loader. As our text is rather short, we can afford to build all center / context pairs in memory when the dataset is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7549e100-c8fa-474c-b379-b4aa38a38869",
   "metadata": {
    "id": "7549e100-c8fa-474c-b379-b4aa38a38869",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CBOWDataSet(torch.utils.data.Dataset):\n",
    "\n",
    "    def yield_context(self, paragraphs):\n",
    "        window_size = self._window_size\n",
    "        for p in paragraphs:\n",
    "            half = window_size // 2\n",
    "            for index, center in  enumerate(p):\n",
    "                context = p[max(0, index - half):index]\n",
    "                context.extend(p[index + 1:min(len(p), index + half + 1)])\n",
    "                yield center, context\n",
    "    \n",
    "    def __init__(self, min_freq = 50, window_size = 8):\n",
    "        super().__init__()\n",
    "        self._window_size = window_size\n",
    "        #\n",
    "        # Build vocabulary\n",
    "        #\n",
    "        ds = torchtext.datasets.WikiText2(split=\"train\")\n",
    "        tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "        paragraphs = []\n",
    "        for item in ds:\n",
    "            # Remove trailing whitespace and special characters\n",
    "            item = re.sub(\"^\\s+\", \"\", item)\n",
    "            item = re.sub(\"@\", \"\", item)\n",
    "            if not re.match(\"^=\", item):\n",
    "                p = tokenizer(item)\n",
    "                if len(p):\n",
    "                    paragraphs.append(p)\n",
    "        self._vocab = torchtext.vocab.build_vocab_from_iterator(paragraphs, min_freq=min_freq, specials=[\"<unk>\"])\n",
    "        self._vocab.set_default_index(self._vocab[\"<unk>\"])\n",
    "        #\n",
    "        # Encode paragraphs\n",
    "        #\n",
    "        encoded_paragraphs = [[self._vocab[_token] for _token in p] for p in paragraphs]\n",
    "       #\n",
    "        # Create a list of all center / context pairs\n",
    "        #\n",
    "        self._x = []\n",
    "        self._y = []\n",
    "        for center, context in self.yield_context(encoded_paragraphs):\n",
    "            if len(context) == self._window_size:\n",
    "                self._x.append(center)\n",
    "                self._y.append(context)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        if index < len(self._x):\n",
    "            return self._x[index], self._y[index]\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._x)\n",
    "\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self._vocab\n",
    "\n",
    "    \n",
    "def collate_fn(list):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index, [center, context] in enumerate(list):\n",
    "        Y.append(context)\n",
    "        X.append(center)\n",
    "            \n",
    "    X = torch.tensor(X, dtype=torch.long)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "    return X, Y \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baac3f2d-a230-43ef-b600-42d1b497d557",
   "metadata": {
    "id": "baac3f2d-a230-43ef-b600-42d1b497d557",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = CBOWDataSet(min_freq=50)\n",
    "BATCH_SIZE = 4\n",
    "training_data = torch.utils.data.DataLoader(ds, batch_size = BATCH_SIZE, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab7763-385b-4acf-a3f0-dea7e893189a",
   "metadata": {
    "id": "69ab7763-385b-4acf-a3f0-dea7e893189a"
   },
   "source": [
    "Let us try this. We expect that each batch consists of two tensor of dimensions $B$ (the batch size) respectively $B \\times W$ where $W$ is the window size. Each row corresponds to a center index and a list of context indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f024cb-26e5-403a-b849-ea7f8d90bc1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42f024cb-26e5-403a-b849-ea7f8d90bc1e",
    "outputId": "ee0b1550-c28b-4ca9-9b6b-62aac4e90a60",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'met', 'with', 'positive'] sales ['in', 'japan', ',', 'and']\n",
      "['met', 'with', 'positive', 'sales'] in ['japan', ',', 'and', 'was']\n",
      "['with', 'positive', 'sales', 'in'] japan [',', 'and', 'was', 'praised']\n",
      "['positive', 'sales', 'in', 'japan'] , ['and', 'was', 'praised', 'by']\n",
      "['sales', 'in', 'japan', ','] and ['was', 'praised', 'by', 'both']\n",
      "['in', 'japan', ',', 'and'] was ['praised', 'by', 'both', 'japanese']\n",
      "['japan', ',', 'and', 'was'] praised ['by', 'both', 'japanese', 'and']\n",
      "[',', 'and', 'was', 'praised'] by ['both', 'japanese', 'and', 'western']\n"
     ]
    }
   ],
   "source": [
    "iter = training_data.__iter__()\n",
    "for i in range(50):\n",
    "    next(iter)\n",
    "for i in range(2):\n",
    "    X, Y = next(iter)\n",
    "    for b in range(BATCH_SIZE):\n",
    "        x, y = X[b].item(), Y[b].tolist()\n",
    "        print_sample(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8403fec-6888-4261-a010-b2e894d528d2",
   "metadata": {
    "id": "e8403fec-6888-4261-a010-b2e894d528d2"
   },
   "source": [
    "Next we build our model - we use a PyTorch embedding, which is essentially a matrix, where the number of embedding is the size of the vocabulary and the dimension is the model dimension which we can choose freely. On top of the embedding, we have a linear layer which translates back from the model dimension into the vocabulary. As recommended in [this blog post](https://towardsdatascience.com/word2vec-with-pytorch-implementing-original-paper-2cd7040120b0), I use the *max_norm* parameter of the embedding to avoid overtraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec218d6-2c88-46a1-ad64-b3df27bf5743",
   "metadata": {
    "id": "9ec218d6-2c88-46a1-ad64-b3df27bf5743",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBED_MAX_NORM = 1\n",
    "\n",
    "class CBOW(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, model_dim, V, bias = False):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=V,\n",
    "            embedding_dim=model_dim,\n",
    "            max_norm=EMBED_MAX_NORM,\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(\n",
    "            in_features=model_dim,\n",
    "            out_features=V,\n",
    "            bias = bias\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, Y):\n",
    "        E = self.embedding(Y).mean(axis=1)\n",
    "        U = self.linear(E)\n",
    "        return U\n",
    "        \n",
    "   \n",
    "    def get_embedding(self, index):\n",
    "        with torch.no_grad():\n",
    "            return self.embedding(torch.tensor([index], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75efa4be-9673-483f-ad05-2e0c7c7df0fa",
   "metadata": {
    "id": "75efa4be-9673-483f-ad05-2e0c7c7df0fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def train(model, epochs, train_data_loader, lr = 0.00025, device = \"cpu\", loss_fn = torch.nn.functional.cross_entropy):\n",
    "    losses = []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    lr_lambda = lambda epoch: (epochs - epoch) / epochs\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda, verbose = False)\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        items_in_epoch = 0\n",
    "        for X, Y in tqdm.tqdm(train_data_loader,  desc = f\"Epoch {epoch}\"):\n",
    "            items_in_epoch = items_in_epoch + 1\n",
    "            f = model(Y.to(device))\n",
    "            targets = X.to(device)\n",
    "            loss = loss_fn(f, targets)            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss / items_in_epoch\n",
    "        print(f\"Completed epoch {epoch}, mean loss in epoch is {epoch_loss}. Current learning rate is {optimizer.param_groups[0]['lr']}\")\n",
    "        scheduler.step()\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc0bb2-3a47-4c05-8bd3-c32933e8e095",
   "metadata": {
    "id": "bbbc0bb2-3a47-4c05-8bd3-c32933e8e095"
   },
   "source": [
    "Let us now train. I found that large batch sizes and large learning rates work well in combination with the Adam optimizer. We do of course train on the GPU if that is available. We plot the losses after completing the training and save the results. I found that with the chosen parameters, 5 - 10 epochs are sufficient to produce reasonable results. Even on my not so modern GPU, this took less than 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ea1efd-4b26-4e72-b547-f1543c981f3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8ea1efd-4b26-4e72-b547-f1543c981f3d",
    "outputId": "efa5ff4b-13be-4768-9c4d-ace8fc7177b7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Size of vocabulary: 4056\n",
      "CBOW(\n",
      "  (embedding): Embedding(4056, 300, max_norm=1)\n",
      "  (linear): Linear(in_features=300, out_features=4056, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device {device}\")\n",
    "D = 300\n",
    "BATCH_SIZE = 20000\n",
    "V = len(ds.get_vocab())\n",
    "print(f\"Size of vocabulary: {V}\")\n",
    "model = CBOW(model_dim=D, V=V, bias = False)\n",
    "print(model)\n",
    "model = model.to(device)\n",
    "    \n",
    "training_data = torch.utils.data.DataLoader(ds, batch_size = BATCH_SIZE, collate_fn = collate_fn, shuffle = True, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b31b900-bd89-4770-985c-602c207af799",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b31b900-bd89-4770-985c-602c207af799",
    "outputId": "f8d4426e-4b2a-4049-ba95-f1a707a692e1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 0, mean loss in epoch is 5.3891845364724436. Current learning rate is 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 1, mean loss in epoch is 4.903358582527407. Current learning rate is 0.08571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 2, mean loss in epoch is 4.777398827255413. Current learning rate is 0.07142857142857144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 3, mean loss in epoch is 4.68927211658929. Current learning rate is 0.05714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 4, mean loss in epoch is 4.628661350537372. Current learning rate is 0.04285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 5, mean loss in epoch is 4.567510220312303. Current learning rate is 0.02857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 6, mean loss in epoch is 4.486164754436862. Current learning rate is 0.014285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = train(model, lr=0.1, epochs=7, train_data_loader = training_data, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f147ca08-811e-4959-a16a-a5852a8e6390",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "f147ca08-811e-4959-a16a-a5852a8e6390",
    "outputId": "c2bf5c93-c35e-41fa-a0c1-ba7798d6297f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe05a3736d0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1395ca-e719-4230-8e17-f639605a837b",
   "metadata": {
    "id": "1e1395ca-e719-4230-8e17-f639605a837b"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Save embeddings and vocab for later use\n",
    "#\n",
    "torch.save(model.embedding.weight, \"context_embeddings.pt\")\n",
    "torch.save(model.linear.weight, \"center_embeddings.pt\")\n",
    "torch.save(ds.get_vocab(), \"vocab.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ae08a2-4ca6-43a0-8f0b-6d7a3e860b27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0ae08a2-4ca6-43a0-8f0b-6d7a3e860b27",
    "outputId": "f96118e0-6c5d-43cb-ed48-674530501d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = 4056, D = 300\n",
      "Shape of context embeddings: torch.Size([4056, 300])\n",
      "Shape of center embeddings:  torch.Size([4056, 300])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load embeddings and vocab. Note that the embeddings are stored \n",
    "# with dimensions V x D, so the embeddings are the rows\n",
    "#\n",
    "vocab = torch.load(\"vocab.pt\")\n",
    "context_embeddings = torch.load(\"context_embeddings.pt\")\n",
    "center_embeddings = torch.load(\"center_embeddings.pt\")\n",
    "V = len(vocab)\n",
    "D = context_embeddings.shape[1]\n",
    "print(f\"V = {V}, D = {D}\")\n",
    "print(f\"Shape of context embeddings: {context_embeddings.shape}\")\n",
    "print(f\"Shape of center embeddings:  {center_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9741b7d-b62e-4f47-b175-19992029c50a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9741b7d-b62e-4f47-b175-19992029c50a",
    "outputId": "3c1d6cf1-2a9c-4a29-a3c9-4f1cdbc6f763",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar token for france\n",
      "      france -- 0.9999999403953552\n",
      "      italy -- 0.661055326461792\n",
      "      germany -- 0.6301742792129517\n",
      "      japan -- 0.62759929895401\n",
      "      australia -- 0.620962917804718\n",
      "Most similar token for king\n",
      "      king -- 0.9999999403953552\n",
      "      son -- 0.5954159498214722\n",
      "      earl -- 0.59091717004776\n",
      "      archbishop -- 0.57264244556427\n",
      "      pope -- 0.5617164969444275\n",
      "Most similar token for father\n",
      "      father -- 1.0000001192092896\n",
      "      mother -- 0.7656291127204895\n",
      "      son -- 0.7561269998550415\n",
      "      daughter -- 0.7459317445755005\n",
      "      wife -- 0.7104585766792297\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Print the 5 most similar words for a given token\n",
    "#\n",
    "def print_most_similar(token, embeddings, vocab):\n",
    "    #\n",
    "    # Normalize embeddings\n",
    "    #\n",
    "    _embeddings = torch.nn.functional.normalize(embeddings, dim = 1)\n",
    "    #\n",
    "    # get u, the embedding of our token\n",
    "    #\n",
    "    u = _embeddings[vocab[token], :]\n",
    "    #\n",
    "    # Now we need to perform the dot product of u with every other word, i.e. with\n",
    "    # every row of _embeddings. But this simply amounts to taking the matrix product\n",
    "    #\n",
    "    v = torch.matmul(_embeddings, u)\n",
    "    #\n",
    "    # Sort this\n",
    "    #\n",
    "    values, indices = torch.sort(v, descending=True)\n",
    "    print(f\"Most similar token for {token}\")\n",
    "    for i in range(5):\n",
    "        print(f\"      {vocab.lookup_token(indices[i])} -- {values[i]}\")\n",
    "    \n",
    "print_most_similar(\"france\", context_embeddings, vocab)\n",
    "print_most_similar(\"king\", context_embeddings, vocab)\n",
    "print_most_similar(\"father\", context_embeddings, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6TZ4r5XVzHEm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TZ4r5XVzHEm",
    "outputId": "cd6518b2-2392-42e2-ba90-5df5a664a446",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar token for france\n",
      "      france -- 1.0\n",
      "      italy -- 0.7698928117752075\n",
      "      spain -- 0.6993325352668762\n",
      "      germany -- 0.6846596598625183\n",
      "      russia -- 0.6496986746788025\n",
      "Most similar token for king\n",
      "      king -- 1.0\n",
      "      pope -- 0.6784377694129944\n",
      "      lord -- 0.6100903749465942\n",
      "      henry -- 0.5989689230918884\n",
      "      queen -- 0.5779016017913818\n",
      "Most similar token for father\n",
      "      father -- 0.9999999403953552\n",
      "      mother -- 0.8434839248657227\n",
      "      wife -- 0.7766066789627075\n",
      "      daughter -- 0.774500846862793\n",
      "      brother -- 0.7713660597801208\n"
     ]
    }
   ],
   "source": [
    "print_most_similar(\"france\", center_embeddings, vocab)\n",
    "print_most_similar(\"king\", center_embeddings, vocab)\n",
    "print_most_similar(\"father\", center_embeddings, vocab)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "MLLM",
   "language": "python",
   "name": "mllm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

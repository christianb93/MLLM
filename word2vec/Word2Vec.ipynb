{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37566b11-bf6a-4f65-bb5c-9272f5e3bd33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37566b11-bf6a-4f65-bb5c-9272f5e3bd33",
    "outputId": "37af9d3c-da88-450a-bd63-886d4849786b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Check that PyTorch is properly installed\n",
    "#\n",
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c4d8c1-a8a6-4ee2-b812-549f6bfd271f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5c4d8c1-a8a6-4ee2-b812-549f6bfd271f",
    "outputId": "42c1b774-8eb0-4f55-a91f-77f9fab5863e"
   },
   "outputs": [],
   "source": [
    "!pip3 install torchtext portalocker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eed12e-1353-44aa-a064-5696951c4506",
   "metadata": {
    "id": "41eed12e-1353-44aa-a064-5696951c4506"
   },
   "source": [
    "First we need to download the WikiText2 dataset. The dataset consists of individual paragraphs, some of which are titles. We go through all paragraphs, clean them, and add all remaining paragraphs into a list. Note that we maintain the structure of paragraphs instead of merging all of them into a single list, as we want to avoid creating center and context pairs that span across paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0815b915-2fa3-43f1-843e-c05c01db1eac",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0815b915-2fa3-43f1-843e-c05c01db1eac",
    "outputId": "78e33413-1e13-457e-c968-739c04b00628",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'the', 'early', 'hours', 'of', '7', 'october', 'the', 'allied', 'artillery', 'and', 'mortar', 'bombardment', 'began', ',', 'targeting', 'chinese', 'positions', 'on', 'the', 'hinge', '.', 'hassett', 'moved', 'the', '3', 'rar', 'tactical', 'headquarters', 'on', 'to', 'hill', '317', 'just', 'before', 'the', 'assaulting', 'troops', 'stepped', 'off', 'the', 'line', 'of', 'departure', ',', 'allowing', 'him', 'to', 'direct', 'the', 'battle', 'from', 'a', 'forward', 'position', 'and', 'to', 'co', '-', '<unk>', 'fire', 'support', '.', 'waiting', 'for', 'the', 'fog', 'to', 'lift', 'so', 'that', 'the', 'artillery', 'could', 'fire', 'until', 'the', 'last', 'safe', 'moment', ',', 'the', 'attack', 'finally', 'began', 'at', '08', '00', '.', 'b', 'company', 'moved', 'off', 'down', 'the', '<unk>', ',', 'with', 'two', '-', 'up', 'and', 'one', '-', 'in', '-', 'depth', ',', 'using', 'the', 'trees', 'and', 'long', 'grass', 'for', 'concealment', '.', 'initially', 'it', 'seemed', 'that', 'the', 'chinese', 'had', 'withdrawn', 'during', 'the', 'night', ',', 'when', 'suddenly', 'the', 'lead', 'australian', 'platoons', 'were', '<unk>', 'by', 'small', 'arms', 'fire', 'from', 'their', 'rear', '.', 'a', 'series', 'of', 'intense', 'fire', '-', 'fights', 'ensued', 'as', 'the', 'australians', 'fought', 'back', 'and', 'by', '09', '20', 'the', 'hinge', 'finally', 'fell', ',', 'with', 'the', 'australians', 'losing', 'two', 'killed', 'and', '20', 'wounded', '.', 'chinese', 'casualties', 'included', 'more', 'than', '20', 'killed', '.', 'as', 'a', 'result', 'of', 'the', 'fighting', 'captain', 'henry', 'nicholls', 'and', 'lieutenant', 'jim', 'hughes', 'were', 'awarded', 'the', 'military', 'cross', ',', 'while', '<unk>', 'j', '.', 'park', 'and', '<unk>', '<unk>', 'bosworth', 'were', 'awarded', 'the', 'military', 'medal', '.', 'yet', 'even', 'as', 'the', 'surviving', 'chinese', 'withdrew', ',', 'artillery', 'and', 'mortar', 'fire', 'began', 'to', 'fall', 'on', 'the', 'hinge', '.', 'b', 'company', 'moved', 'quickly', 'to', 'consolidate', 'the', 'position', ',', 'but', 'were', 'hampered', 'by', 'the', 'shelling', ',', 'while', 'they', 'now', 'faced', 'a', 'pressing', 'shortage', 'of', 'ammunition', 'and', 'difficulties', 'evacuating', 'their', 'casualties', '.']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import torchtext\n",
    "import collections\n",
    "\n",
    "\n",
    "def to_paragraphs(_items, tokenizer):\n",
    "    paragraphs = []\n",
    "    for item in _items:\n",
    "        # Remove trailing whitespace and special characters\n",
    "        item = re.sub(\"^\\s+\", \"\", item)\n",
    "        item = re.sub(\"@\", \"\", item)\n",
    "        if not re.match(\"^=\", item):\n",
    "            p = tokenizer(item)\n",
    "            if len(p):\n",
    "                paragraphs.append(p)\n",
    "                        \n",
    "    return paragraphs\n",
    "\n",
    "#\n",
    "# Build list of paragraphs and print a sample\n",
    "#\n",
    "ds = torchtext.datasets.WikiText2(split=\"train\")\n",
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "paragraphs = to_paragraphs(ds, tokenizer)\n",
    "print(paragraphs[5000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c296d54-d168-4bfd-b1e8-1242d6f33ac6",
   "metadata": {
    "id": "7c296d54-d168-4bfd-b1e8-1242d6f33ac6"
   },
   "source": [
    "Next we again tokenize the text and build a vocabulary. However, this time we will ignore all words that appear less than a given number of times in the text, and instead use a special token in the vocabulary that will be used for all token that are not in the vocabulary during encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa415ca2-e674-4acb-8565-71a41798a809",
   "metadata": {
    "id": "fa415ca2-e674-4acb-8565-71a41798a809",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vocab(paragraphs, min_freq = 50):\n",
    "        vocab = torchtext.vocab.build_vocab_from_iterator(paragraphs, min_freq=min_freq, specials=[\"<unk>\"])\n",
    "        vocab.set_default_index(vocab[\"<unk>\"])\n",
    "        return vocab\n",
    "\n",
    "def encode_paragraphs(paragraphs, vocab):\n",
    "    return [[vocab[_token] for _token in p] for p in paragraphs]\n",
    "\n",
    "vocab = build_vocab(paragraphs)\n",
    "encoded_paragraphs = encode_paragraphs(paragraphs, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9a02a-a2d9-421c-880b-b1250f0ed602",
   "metadata": {
    "id": "08a9a02a-a2d9-421c-880b-b1250f0ed602"
   },
   "source": [
    "The next step in the processing is to create pairs consisting of a center token and a list of context tokens. We will do this paragraph for paragraph and later skip outputs which are two short. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee1b3b7-0df9-4890-843b-d156d64a310e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dee1b3b7-0df9-4890-843b-d156d64a310e",
    "outputId": "1d1c526f-b883-4b4d-cbd9-f1842239b303",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('This', ['is', 'a'])\n",
      "('is', ['This', 'a', 'short'])\n",
      "('a', ['This', 'is', 'short', 'test'])\n",
      "('short', ['is', 'a', 'test', 'paragraph'])\n",
      "('test', ['a', 'short', 'paragraph', 'to'])\n",
      "('paragraph', ['short', 'test', 'to', 'try'])\n",
      "('to', ['test', 'paragraph', 'try', 'out'])\n",
      "('try', ['paragraph', 'to', 'out', 'things'])\n",
      "('out', ['to', 'try', 'things'])\n",
      "('things', ['try', 'out'])\n"
     ]
    }
   ],
   "source": [
    "def yield_context(paragraphs, window_size = 8):\n",
    "    for p in paragraphs:\n",
    "        half = window_size // 2\n",
    "        #\n",
    "        # If we are not yet at the last token in the paragraph, \n",
    "        # yield window and advance center. \n",
    "        #\n",
    "        for index, center in  enumerate(p):\n",
    "            context = p[max(0, index - half):index]\n",
    "            context.extend(p[index + 1:min(len(p), index + half + 1)])\n",
    "            yield center, context\n",
    "\n",
    "test_paragraphs = [[\"This\", \"is\", \"a\", \"short\", \"test\", \"paragraph\", \"to\", \"try\", \"out\", \"things\"]]\n",
    "iter = yield_context(test_paragraphs, window_size = 4)\n",
    "for i in range(10):\n",
    "  print(next(iter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca21a6e-062a-4206-a78a-1adaa24cc130",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ca21a6e-062a-4206-a78a-1adaa24cc130",
    "outputId": "61bba339-4397-4b5a-d3bb-0b54279810b5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['17', 'team', 'of', '24'] players [',', '<unk>', 'from', 'an']\n",
      "['team', 'of', '24', 'players'] , ['<unk>', 'from', 'an', 'initial']\n",
      "['of', '24', 'players', ','] <unk> ['from', 'an', 'initial', 'pool']\n",
      "['24', 'players', ',', '<unk>'] from ['an', 'initial', 'pool', 'of']\n",
      "['players', ',', '<unk>', 'from'] an ['initial', 'pool', 'of', '49']\n",
      "[',', '<unk>', 'from', 'an'] initial ['pool', 'of', '49', 'young']\n",
      "['<unk>', 'from', 'an', 'initial'] pool ['of', '49', 'young', 'women']\n",
      "['from', 'an', 'initial', 'pool'] of ['49', 'young', 'women', '.']\n",
      "['an', 'initial', 'pool', 'of'] 49 ['young', 'women', '.', 'two']\n",
      "['initial', 'pool', 'of', '49'] young ['women', '.', 'two', 'girls']\n"
     ]
    }
   ],
   "source": [
    "def print_sample(center, context):\n",
    "    left_context = context[:len(context) // 2]\n",
    "    right_context = context[len(context) // 2:]\n",
    "    print(f\"{[vocab.lookup_token(idx) for idx in left_context]} {vocab.lookup_token(center)} {[vocab.lookup_token(idx) for idx in right_context]}\")\n",
    "    \n",
    "iter = yield_context(encoded_paragraphs)\n",
    "#\n",
    "# Advance by a few items, then print a few examples\n",
    "#\n",
    "for i in range(10800):\n",
    "    next(iter)\n",
    "for i in range(10):\n",
    "    center, context = next(iter)\n",
    "    if len(context) != 8:\n",
    "        continue\n",
    "    print_sample(center, context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f092890-a369-47e7-94f3-5bc44187bec5",
   "metadata": {
    "id": "4f092890-a369-47e7-94f3-5bc44187bec5"
   },
   "source": [
    "We are now ready to put all this into a PyTorch data set, use a data loader to load a batch and print a few examples from the batch to verify that our code works. This is not an introduction into datasets, but basically a dataset is an object that implements *__getitem__* and *__len__* so that it can be handled by a data loader. As our text is rather short, we can afford to build all center / context pairs in memory when the dataset is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7549e100-c8fa-474c-b379-b4aa38a38869",
   "metadata": {
    "id": "7549e100-c8fa-474c-b379-b4aa38a38869",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CBOWDataSet(torch.utils.data.Dataset):\n",
    "\n",
    "    def yield_context(self, paragraphs):\n",
    "        window_size = self._window_size\n",
    "        for p in paragraphs:\n",
    "            half = window_size // 2\n",
    "            for index, center in  enumerate(p):\n",
    "                context = p[max(0, index - half):index]\n",
    "                context.extend(p[index + 1:min(len(p), index + half + 1)])\n",
    "                yield center, context\n",
    "    \n",
    "    def __init__(self, min_freq = 50, window_size = 8):\n",
    "        super().__init__()\n",
    "        self._window_size = window_size\n",
    "        #\n",
    "        # Build vocabulary\n",
    "        #\n",
    "        ds = torchtext.datasets.WikiText2(split=\"train\")\n",
    "        tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "        paragraphs = []\n",
    "        for item in ds:\n",
    "            # Remove trailing whitespace and special characters\n",
    "            item = re.sub(\"^\\s+\", \"\", item)\n",
    "            item = re.sub(\"@\", \"\", item)\n",
    "            if not re.match(\"^=\", item):\n",
    "                p = tokenizer(item)\n",
    "                if len(p):\n",
    "                    paragraphs.append(p)\n",
    "        self._vocab = torchtext.vocab.build_vocab_from_iterator(paragraphs, min_freq=min_freq, specials=[\"<unk>\"])\n",
    "        self._vocab.set_default_index(self._vocab[\"<unk>\"])\n",
    "        #\n",
    "        # Encode paragraphs\n",
    "        #\n",
    "        encoded_paragraphs = [[self._vocab[_token] for _token in p] for p in paragraphs]\n",
    "       #\n",
    "        # Create a list of all center / context pairs\n",
    "        #\n",
    "        self._x = []\n",
    "        self._y = []\n",
    "        for center, context in self.yield_context(encoded_paragraphs):\n",
    "            if len(context) == self._window_size:\n",
    "                self._x.append(center)\n",
    "                self._y.append(context)\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        if index < len(self._x):\n",
    "            return self._x[index], self._y[index]\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._x)\n",
    "\n",
    "    \n",
    "    def get_vocab(self):\n",
    "        return self._vocab\n",
    "\n",
    "    \n",
    "def collate_fn(list):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for index, [center, context] in enumerate(list):\n",
    "        Y.append(context)\n",
    "        X.append(center)\n",
    "            \n",
    "    X = torch.tensor(X, dtype=torch.long)\n",
    "    Y = torch.tensor(Y, dtype=torch.long)\n",
    "    return X, Y \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baac3f2d-a230-43ef-b600-42d1b497d557",
   "metadata": {
    "id": "baac3f2d-a230-43ef-b600-42d1b497d557",
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds = CBOWDataSet(min_freq=50)\n",
    "BATCH_SIZE = 4\n",
    "training_data = torch.utils.data.DataLoader(ds, batch_size = BATCH_SIZE, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ab7763-385b-4acf-a3f0-dea7e893189a",
   "metadata": {
    "id": "69ab7763-385b-4acf-a3f0-dea7e893189a"
   },
   "source": [
    "Let us try this. We expect that each batch consists of two tensor of dimensions $B$ (the batch size) respectively $B \\times W$ where $W$ is the window size. Each row corresponds to a center index and a list of context indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42f024cb-26e5-403a-b849-ea7f8d90bc1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "42f024cb-26e5-403a-b849-ea7f8d90bc1e",
    "outputId": "ee0b1550-c28b-4ca9-9b6b-62aac4e90a60",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'met', 'with', 'positive'] sales ['in', 'japan', ',', 'and']\n",
      "['met', 'with', 'positive', 'sales'] in ['japan', ',', 'and', 'was']\n",
      "['with', 'positive', 'sales', 'in'] japan [',', 'and', 'was', 'praised']\n",
      "['positive', 'sales', 'in', 'japan'] , ['and', 'was', 'praised', 'by']\n",
      "['sales', 'in', 'japan', ','] and ['was', 'praised', 'by', 'both']\n",
      "['in', 'japan', ',', 'and'] was ['praised', 'by', 'both', 'japanese']\n",
      "['japan', ',', 'and', 'was'] praised ['by', 'both', 'japanese', 'and']\n",
      "[',', 'and', 'was', 'praised'] by ['both', 'japanese', 'and', 'western']\n"
     ]
    }
   ],
   "source": [
    "iter = training_data.__iter__()\n",
    "for i in range(50):\n",
    "    next(iter)\n",
    "for i in range(2):\n",
    "    X, Y = next(iter)\n",
    "    for b in range(BATCH_SIZE):\n",
    "        x, y = X[b].item(), Y[b].tolist()\n",
    "        print_sample(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8403fec-6888-4261-a010-b2e894d528d2",
   "metadata": {
    "id": "e8403fec-6888-4261-a010-b2e894d528d2"
   },
   "source": [
    "Next we build our model - we use a PyTorch embedding, which is essentially a matrix, where the number of embedding is the size of the vocabulary and the dimension is the model dimension which we can choose freely. On top of the embedding, we have a linear layer which translates back from the model dimension into the vocabulary. As recommended in [this blog post](https://towardsdatascience.com/word2vec-with-pytorch-implementing-original-paper-2cd7040120b0), I use the *max_norm* parameter of the embedding to avoid overtraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ec218d6-2c88-46a1-ad64-b3df27bf5743",
   "metadata": {
    "id": "9ec218d6-2c88-46a1-ad64-b3df27bf5743",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EMBED_MAX_NORM = 1\n",
    "\n",
    "class CBOW(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, model_dim, V, bias = False):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(\n",
    "            num_embeddings=V,\n",
    "            embedding_dim=model_dim,\n",
    "            max_norm=EMBED_MAX_NORM,\n",
    "        )\n",
    "        self.linear = torch.nn.Linear(\n",
    "            in_features=model_dim,\n",
    "            out_features=V,\n",
    "            bias = bias\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, Y):\n",
    "        E = self.embedding(Y).mean(axis=1)\n",
    "        U = self.linear(E)\n",
    "        return U\n",
    "        \n",
    "   \n",
    "    def get_embedding(self, index):\n",
    "        with torch.no_grad():\n",
    "            return self.embedding(torch.tensor([index], dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75efa4be-9673-483f-ad05-2e0c7c7df0fa",
   "metadata": {
    "id": "75efa4be-9673-483f-ad05-2e0c7c7df0fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def train(model, epochs, train_data_loader, lr = 0.00025, device = \"cpu\", loss_fn = torch.nn.functional.cross_entropy):\n",
    "    losses = []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "    lr_lambda = lambda epoch: (epochs - epoch) / epochs\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda, verbose = False)\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        items_in_epoch = 0\n",
    "        for X, Y in tqdm.tqdm(train_data_loader,  desc = f\"Epoch {epoch}\"):\n",
    "            items_in_epoch = items_in_epoch + 1\n",
    "            f = model(Y.to(device))\n",
    "            targets = X.to(device)\n",
    "            loss = loss_fn(f, targets)            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "\n",
    "        epoch_loss = epoch_loss / items_in_epoch\n",
    "        print(f\"Completed epoch {epoch}, mean loss in epoch is {epoch_loss}. Current learning rate is {optimizer.param_groups[0]['lr']}\")\n",
    "        scheduler.step()\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbc0bb2-3a47-4c05-8bd3-c32933e8e095",
   "metadata": {
    "id": "bbbc0bb2-3a47-4c05-8bd3-c32933e8e095"
   },
   "source": [
    "Let us now train. I found that large batch sizes and large learning rates work well in combination with the Adam optimizer. We do of course train on the GPU if that is available. We plot the losses after completing the training and save the results. I found that with the chosen parameters, 5 - 10 epochs are sufficient to produce reasonable results. Even on my not so modern GPU, this took less than 2 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8ea1efd-4b26-4e72-b547-f1543c981f3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f8ea1efd-4b26-4e72-b547-f1543c981f3d",
    "outputId": "efa5ff4b-13be-4768-9c4d-ace8fc7177b7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda\n",
      "Size of vocabulary: 4056\n",
      "CBOW(\n",
      "  (embedding): Embedding(4056, 300, max_norm=1)\n",
      "  (linear): Linear(in_features=300, out_features=4056, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device {device}\")\n",
    "D = 300\n",
    "BATCH_SIZE = 20000\n",
    "V = len(ds.get_vocab())\n",
    "print(f\"Size of vocabulary: {V}\")\n",
    "model = CBOW(model_dim=D, V=V, bias = False)\n",
    "print(model)\n",
    "model = model.to(device)\n",
    "    \n",
    "training_data = torch.utils.data.DataLoader(ds, batch_size = BATCH_SIZE, collate_fn = collate_fn, shuffle = True, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b31b900-bd89-4770-985c-602c207af799",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5b31b900-bd89-4770-985c-602c207af799",
    "outputId": "f8d4426e-4b2a-4049-ba95-f1a707a692e1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 0, mean loss in epoch is 5.384986067330965. Current learning rate is 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 1, mean loss in epoch is 4.912747911227647. Current learning rate is 0.08571428571428572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 2, mean loss in epoch is 4.765877031510876. Current learning rate is 0.07142857142857144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 3, mean loss in epoch is 4.689463015525572. Current learning rate is 0.05714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 4, mean loss in epoch is 4.625309380151892. Current learning rate is 0.04285714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 5, mean loss in epoch is 4.565894480674498. Current learning rate is 0.02857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 93/93 [00:08<00:00, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed epoch 6, mean loss in epoch is 4.485608782819522. Current learning rate is 0.014285714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "losses = train(model, lr=0.1, epochs=7, train_data_loader = training_data, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f147ca08-811e-4959-a16a-a5852a8e6390",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "f147ca08-811e-4959-a16a-a5852a8e6390",
    "outputId": "c2bf5c93-c35e-41fa-a0c1-ba7798d6297f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98b30df760>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e1395ca-e719-4230-8e17-f639605a837b",
   "metadata": {
    "id": "1e1395ca-e719-4230-8e17-f639605a837b"
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Save embeddings and vocab for later use\n",
    "#\n",
    "torch.save(model.embedding.weight, \"context_embeddings.pt\")\n",
    "torch.save(model.linear.weight, \"center_embeddings.pt\")\n",
    "torch.save(ds.get_vocab(), \"vocab.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0ae08a2-4ca6-43a0-8f0b-6d7a3e860b27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0ae08a2-4ca6-43a0-8f0b-6d7a3e860b27",
    "outputId": "f96118e0-6c5d-43cb-ed48-674530501d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = 4056, D = 300\n",
      "Shape of context embeddings: torch.Size([4056, 300])\n",
      "Shape of center embeddings:  torch.Size([4056, 300])\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Load embeddings and vocab. Note that the embeddings are stored \n",
    "# with dimensions V x D, so the embeddings are the rows\n",
    "#\n",
    "vocab = torch.load(\"vocab.pt\")\n",
    "context_embeddings = torch.load(\"context_embeddings.pt\")\n",
    "center_embeddings = torch.load(\"center_embeddings.pt\")\n",
    "V = len(vocab)\n",
    "D = context_embeddings.shape[1]\n",
    "print(f\"V = {V}, D = {D}\")\n",
    "print(f\"Shape of context embeddings: {context_embeddings.shape}\")\n",
    "print(f\"Shape of center embeddings:  {center_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9741b7d-b62e-4f47-b175-19992029c50a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e9741b7d-b62e-4f47-b175-19992029c50a",
    "outputId": "3c1d6cf1-2a9c-4a29-a3c9-4f1cdbc6f763",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar token for france\n",
      "      france -- 0.9999999403953552\n",
      "      spain -- 0.6880383491516113\n",
      "      italy -- 0.6732332706451416\n",
      "      argentina -- 0.6491516828536987\n",
      "      germany -- 0.646877646446228\n",
      "Most similar token for king\n",
      "      king -- 1.0000001192092896\n",
      "      pope -- 0.6250259876251221\n",
      "      gerard -- 0.5856004953384399\n",
      "      monarch -- 0.5732649564743042\n",
      "      bishop -- 0.5599410533905029\n",
      "Most similar token for father\n",
      "      father -- 1.0000001192092896\n",
      "      wife -- 0.7066431045532227\n",
      "      mother -- 0.7002478837966919\n",
      "      brother -- 0.646498441696167\n",
      "      son -- 0.644016444683075\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Print the 5 most similar words for a given token\n",
    "#\n",
    "def print_most_similar(token, embeddings, vocab):\n",
    "    #\n",
    "    # Normalize embeddings\n",
    "    #\n",
    "    _embeddings = torch.nn.functional.normalize(embeddings, dim = 1)\n",
    "    #\n",
    "    # get u, the embedding of our token\n",
    "    #\n",
    "    u = _embeddings[vocab[token], :]\n",
    "    #\n",
    "    # Now we need to perform the dot product of u with every other word, i.e. with\n",
    "    # every row of _embeddings. But this simply amounts to taking the matrix product\n",
    "    #\n",
    "    v = torch.matmul(_embeddings, u)\n",
    "    #\n",
    "    # Sort this\n",
    "    #\n",
    "    values, indices = torch.sort(v, descending=True)\n",
    "    print(f\"Most similar token for {token}\")\n",
    "    for i in range(5):\n",
    "        print(f\"      {vocab.lookup_token(indices[i])} -- {values[i]}\")\n",
    "    \n",
    "print_most_similar(\"france\", context_embeddings, vocab)\n",
    "print_most_similar(\"king\", context_embeddings, vocab)\n",
    "print_most_similar(\"father\", context_embeddings, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6TZ4r5XVzHEm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6TZ4r5XVzHEm",
    "outputId": "cd6518b2-2392-42e2-ba90-5df5a664a446",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar token for france\n",
      "      france -- 1.0000001192092896\n",
      "      italy -- 0.7553751468658447\n",
      "      spain -- 0.6878049969673157\n",
      "      russia -- 0.664093554019928\n",
      "      germany -- 0.6439176201820374\n",
      "Most similar token for king\n",
      "      king -- 1.0\n",
      "      pope -- 0.6872796416282654\n",
      "      edward -- 0.6148213744163513\n",
      "      henry -- 0.5906969904899597\n",
      "      son -- 0.5880035161972046\n",
      "Most similar token for father\n",
      "      father -- 1.0\n",
      "      mother -- 0.8521094918251038\n",
      "      brother -- 0.7779375314712524\n",
      "      wife -- 0.7714092135429382\n",
      "      daughter -- 0.757207989692688\n"
     ]
    }
   ],
   "source": [
    "print_most_similar(\"france\", center_embeddings, vocab)\n",
    "print_most_similar(\"king\", center_embeddings, vocab)\n",
    "print_most_similar(\"father\", center_embeddings, vocab)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
